{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyObTvYUhrX0/NG1AgEjYHrw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"uVCaCusLJyct","executionInfo":{"status":"ok","timestamp":1714900137674,"user_tz":-420,"elapsed":6289,"user":{"displayName":"Bùi Khắc Minh","userId":"03345941564288769937"}}},"outputs":[],"source":["!pip install transformers datasets -q"]},{"cell_type":"code","source":["!pip install accelerate==0.21.0\n","# !pip install transformers[torch]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwfWFnLyKcUQ","executionInfo":{"status":"ok","timestamp":1714900144081,"user_tz":-420,"elapsed":6410,"user":{"displayName":"Bùi Khắc Minh","userId":"03345941564288769937"}},"outputId":"6fed5869-9977-4844-e563-440e453dbf6b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate==0.21.0 in /usr/local/lib/python3.10/dist-packages (0.21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.21.0) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n"]}]},{"cell_type":"code","source":["import torch\n","# from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","from transformers import BertTokenizerFast, BertForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","import numpy as np\n","import random\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"HAplCjPaJ1rk","executionInfo":{"status":"ok","timestamp":1714900163987,"user_tz":-420,"elapsed":19910,"user":{"displayName":"Bùi Khắc Minh","userId":"03345941564288769937"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# the model we gonna train, base uncased BERT\n","# check text classification models here: https://huggingface.co/models?filter=text-classification\n","model_name = \"bert-base-uncased\"\n","# max sequence length for each document/sentence sample\n","max_length = 512\n","# load the tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDNgaz8hJ45s","executionInfo":{"status":"ok","timestamp":1714900166499,"user_tz":-420,"elapsed":2529,"user":{"displayName":"Bùi Khắc Minh","userId":"03345941564288769937"}},"outputId":"7bf258a8-561f-4445-b8cf-999ed88b3014"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def read_20newsgroups(test_size=0.2):\n","  # download & load 20newsgroups dataset from sklearn's repos\n","  dataset = fetch_20newsgroups(subset=\"all\", shuffle=True, remove=(\"headers\", \"footers\", \"quotes\"))\n","  documents = dataset.data\n","  labels = dataset.target\n","  # split into training & testing a return data as well as label names\n","  return train_test_split(documents, labels, test_size=test_size), dataset.target_names\n","\n","# call the function\n","(train_texts, valid_texts, train_labels, valid_labels), target_names = read_20newsgroups()"],"metadata":{"id":"CzzXx0HZMhts","executionInfo":{"status":"ok","timestamp":1714900169058,"user_tz":-420,"elapsed":2561,"user":{"displayName":"Bùi Khắc Minh","userId":"03345941564288769937"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# tokenize the dataset, truncate when passed `max_length`,\n","# and pad with 0's when less than `max_length`\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n","valid_encodings = tokenizer(valid_texts, truncation=True, padding=True, max_length=max_length)"],"metadata":{"id":"wqNPdFmFMkJF","executionInfo":{"status":"ok","timestamp":1714900194239,"user_tz":-420,"elapsed":25183,"user":{"displayName":"Bùi Khắc Minh","userId":"03345941564288769937"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class NewsGroupsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor([self.labels[idx]])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# convert our tokenized data into a torch Dataset\n","train_dataset = NewsGroupsDataset(train_encodings, train_labels)\n","valid_dataset = NewsGroupsDataset(valid_encodings, valid_labels)"],"metadata":{"id":"nAxHHTe3MoUE","executionInfo":{"status":"ok","timestamp":1714900194240,"user_tz":-420,"elapsed":12,"user":{"displayName":"Bùi Khắc Minh","userId":"03345941564288769937"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# load the model and pass to CUDA\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Al0yFFKFMsaV","executionInfo":{"status":"ok","timestamp":1714900196726,"user_tz":-420,"elapsed":2497,"user":{"displayName":"Bùi Khắc Minh","userId":"03345941564288769937"}},"outputId":"60355f07-42b0-4916-e89f-67cc279cf986"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","import torch.nn as nn\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  return {\n","      'accuracy': acc,\n","  }\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","\n","optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Epochs và batch size\n","num_epochs = 3\n","train_batch_size = 8\n","eval_batch_size = 20\n","\n","# DataLoader cho tập huấn luyện và đánh giá\n","train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n","eval_loader = DataLoader(valid_dataset, batch_size=eval_batch_size)\n","\n"],"metadata":{"id":"HOY6fis1MxTh","executionInfo":{"status":"ok","timestamp":1714900196726,"user_tz":-420,"elapsed":3,"user":{"displayName":"Bùi Khắc Minh","userId":"03345941564288769937"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","def train_epoch(model, dataloader, optimizer, criterion):\n","    model.train()\n","    model.cuda()\n","    running_loss = 0.0\n","    pbar = tqdm(enumerate(dataloader))\n","    for i , dt in pbar:\n","        inputs = dt['input_ids']\n","        targets = dt['labels']\n","        optimizer.zero_grad()\n","        outputs = model(inputs.cuda())\n","        loss = criterion(outputs['logits'].cuda(), targets[:,0].cuda())\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","        pbar.set_description(\"Epoch: {}, Loss: {:4f}\".format(epoch + 1, running_loss/(i+1)))\n","    return running_loss / len(dataloader.dataset)\n","\n","# Hàm đánh giá\n","def evaluate(model, dataloader, criterion):\n","    model.eval()\n","    running_loss = 0.0\n","    with torch.no_grad():\n","        for inputs, targets in dataloader:\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            running_loss += loss.item() * inputs.size(0)\n","    return running_loss / len(dataloader.dataset)"],"metadata":{"id":"5KSwAT7I_1aG","executionInfo":{"status":"ok","timestamp":1714900298597,"user_tz":-420,"elapsed":710,"user":{"displayName":"Bùi Khắc Minh","userId":"03345941564288769937"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n","    val_loss = evaluate(model, eval_loader, criterion)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","    scheduler.step()  # Cập nhật learning rate nếu có\n"],"metadata":{"id":"IRuFuXLD-hEJ"},"execution_count":null,"outputs":[]}]}